Ocean Monitoring Framework based onCompressive Sensing using Acoustic SensorNetworksRahul Mourya, Wael Saan, Mauro Dragone, Yvan PetillotInstitute of Sensors, Signals, and SystemsR.mourya@hw.ac.uk, W.saan@hw.ac.uk, M.dragone@hw.ac.uk, Y.R.Petillot@hw.ac.ukHeirot-Watt University Edinburgh, Scotland, UKAbstract This paper presents a framework for spatio-temporal monitoring of ocean environment using large-scaleunderwater acoustic sensor networks (UWASNs). Our goal is toexploit low-cost, battery-operated technology for acoustic com-munication to enable long-term, mass deployment of UWASNs fora wide range of monitoring applications in need of high spatio-temporal sampling rate and near real-time data delivery. Inspiredby theory of compressive sensing (CS), the framework supportsopportunistic random deployment of sensor nodes and relies onrandom channel access to harvest their data and construct spatio-temporal elds of the underlying sensed phenomena. In order tosave bandwidth and energy, we consider a positioning scheme inwhich the sensor nodes remain silent and just listen for beaconsignals from few reference nodes to localize themselves. After thisinitial localization phase, the sensing process begins. At regularintervals (frames), a set of random sensors sample their transduc-ers and independently try to transmit their measurements to afusion center (FC) for CS-based eld reconstruction. Due to thisrandom access of the acoustic channel, some of the packets maycollide at the FC, wasting both energy and bandwidth. For slowlyvarying elds, consecutive frames have high correlations. Weexploit this information during the eld reconstruction, and showby simulation results that the number of sensors participating ineach frame can be reduced drastically. This decreases the numberof collisions at the FC, thus saving energy and prolonging thelife-time of the network.Index TermsAcoustic sensor networks, silent localization,random access, compressive sensing, convex optimizationI. INTRODUCTIONUnderwater acoustic sensor networks are widely becomingessential enablers for a wide range of applications such re-mote monitoring of ocean environments, marine biodiversity,anticipating natural disasters, underwater assets management,defense and homeland security, to name a few. Often, theserequire long-term deployment of sensor networks. Each sensornode in these networks is typically consists of a modem, somesensor modules, a computational unit for signal processingand network protocols, and a power supply. Acoustic com-munication is often the physical layer technology of choicefor underwater wireless networking, since acoustic wavescan travel long ranges (up to kilometers) while radio andoptical waves die within few meters. However, unlike theterrestrial radio and optical channels, the underwater acousticchannel is constrained by three factors: limited and distance-dependent bandwidth,time-varying multi-path propagation,and low speed of sound [1][3]. Moreover, acoustic modemsare typically limited to half-duplex operation. On top of that,supplying power to the underwater sensor nodes for long-term deployment is also a major concern. All these constraintspose a signicant challenge for developing UWASNs and itsprotocols [4][6].In this paper, we propose a framework for spatio-temporalmonitoring of underwater physical phenomenon by measuringphysical parameters such as temperature, pressure, salinity,oxygen level, etc, using UWASNs. With the recent advancesin technologies, the acoustic modem, sensors and computingunits are getting cheaper, reliable and power efcient, thusthe UWASNs are becoming more realizable. However, thechannel access is still one of the biggest obstacles due lowbandwidth and long propagation delay. There are two maincategories of multiple-access protocols that enable to sharea channel among multiple communicating nodes: determinis-tic and random access. Deterministic access protocols sharethe channel in several ways (e.g. time-division, frequency-division, code-division) and avoid collision between the datapackets. These protocols are suitable for applications that needa steady ow of information. In random access protocols, thenodes transmit their packets whenever they have new datawithout worrying about collisions. These protocols are goodfor applications that has very low-trafc and bursty informa-tion here and there. Several improvements on the standardmultiple access protocols have been proposed in literature;see [4][6] and references within for detailed comparisons.Time division multiple access (TDMA) is one of the simplestdeterministic protocols, but typically requires centralized clocksynchronization among the nodes. Authors in [6] proposeda centralized clock synchronization free TDMA, which is asignicant improvement over standard TDMA. Code divisionmultiple access (CDMA) can outperform TDMA in many as-pects: robustness to frequency-selective fading, compensationfor the effect of multipath by exploiting Rake lters at thereceiver, and enabling receivers to distinguish among signalssimultaneously transmitted by multiple devices. Thus, it can bea promising physical and MAC layer technique for underwatercommunication. However, because of its high-computationalcomplexity, it may not be suitable for low-powered sensornodes in UWASNs.Owing to the fact that most natural phenomenon are com-pressible in an appropriate basis, e.g., smoothly varying eldis sparse in frequency domain, the CS techniques have beenexploited to mitigate the challenges point out earlier. Thetheory of CS states that under certain conditions, exact signalreconstruction is possible with only small number of randommeasurements [7], [8]. Thus, rather than gathering the senseddata sampled by all the sensor nodes at each time frame,only few random nodes need to transmit their measurements.This can reduce signicantly the bandwidth and the energyconsumption required for signal reconstruction. The rst ex-ample application of CS in sensor networks was introducedin [9]. Since then, several works, including [10][14] havebeen published. While quite diverse in the issues addressed(e.g., routing, performance, compressive measurements), mostof those works have considered terrestrial wireless sensornetworks. As such, their results cannot be directly appliedto UWASNs. Fatemeh et al. in [15] proposed random accesscompressed sensing (RACS) scheme for UWASNs, whichis one of the most important work applying CS theory tomitigate the problems faced in data gathering and eld re-construction. Random access protocols in general are verysimple to implement, as they do not require the scheduling oftransmissions, as in TDMA protocols, nor do they need controlsignals to establish collision-free links, as in contention-basedMAC protocols. More recently, [16], [17] proposed interleave-division multiple access (IDMA) based compressive sensingschemes. IDMA is an extension of CDMA inheriting thegood features of CDMA, but also the power hungry highcomputational complexity,thus not suitable for long-termdeployment in oceans.For these reasons, in the proposed framework, we considerthe random channel access scheme proposed in [15]. However,unlike the regular grid deployment of sensor nodes consideredin that work, we consider random deployment of the sensornodes over a given region ROI. Making no assumption on thelocation of the sensor nodes is key to support opportunisticdeployments and generally increase the applicability of themonitoring framework. However, the sensor nodes must belocalized before the sensing process can begin. Sensor networklocalization is a well studied topic; see [18], [19] for asurveys on network localization. Typically, a node localizationis achieved in two steps: i) ranging from at least minimumnumber of reference nodes with known positions, referred to asanchors, and ii) then preforming trilateration or multilaterationor relaxed convex optimization [20], [21].For spatio-temporal eld estimation from random measure-ments, we assume that the eld is varying slowly with thetime, i.e., the two consecutive frames are highly correlatedto each other, which is often the case for natural phenomenawe are interested in. An important key characteristic of ourframework is that, unlike [15], we exploit this informationin eld estimation phase, and show by simulations that thenumber of sensors taking part in measurements and channelaccess during a frame reconstruction can be reduced dras-tically. Effectively, each sensor involves less frequently insensing and transmitting measurements, thus prolonging thelife-time of each sensor node.The remaining paper is organized as follow: In Section II wedescribe the framework with the network model. In Section III,we present the silent localization scheme with some simulationresults showing its performance. In Section IV, we outlinethe spatio-temporal sensing based on compressive sensingand random channel access, and suggest suitable solutionto the convex optimization algorithms for performing eldreconstruction. We show by simulation result how temporalcoherency can be exploited to prolong overall the life-time ofthe network. Finally, Section V draws our conclusions.II. UNDERWATER MONITORING FRAMEWORKConsider a UWASN of M static sensor nodes deployeduniformly at random over ROI. The proposed frameworkfor remote monitoring of ocean environment is consists ofthree main phases: (i) deployment and localization of sensornodes, (ii) random access of acoustic channel to transmit thesensorÅfs measurements to the FC, and (iii) eld reconstructionat the FC from correctly received measurements. The sensornetwork in our framework consists two types of nodes: fewanchors and sufciently many sensor nodes. The nodes havetheir unique identiers, independent (not synchronized) clocksand acoustic modem with omni-directional antenna. A typicalscenario of our framework is shown in Fig.1. Anchors aredeployed on the ocean surface with acoustic modems hangingfew meters below the surface. Thus, anchors can have asufciently large power supply (probably supported by solarpanels), a GPS module, a modem with long acoustic rangesand sufciently powerful computing units. The anchors servetwo purposes: as references for the sensors and gatewaysto the FC. The anchors can communicate with the FC atshore through radio channels, thus have very high bandwidthscompared to underwater acoustic channel. One of the anchorsis considered as a gateway. On other hand, the sensor nodes aredeployed deep into the ocean, have relatively small acousticranges and less demanding computing units. Thus, they aresuitable for powering up by small batteries that can last forlong time (typically for several months).The framework utilize two types of multiple access proto-cols: i) TDMA proposed in [6] for transmitting some criticalinformation that should not be lost e.g., positions of sensors,and ii) random access proposed in [15] for transmitting mea-surements from sensors to the FC. After the localization phase,the sensors transmit their positions to the FC using TDMA.Knowing the positions of the sensors, the FC discretizes thespace into N regular interval zones depending upon resolutionrequired by the application. For example, see Fig. 2 wherea 2-D space is discretized into regular interval zones wherefew of zones have at least a node. For sake of mathematicalsimplicity, we assumed that the nodes lie in the center of thezones.In the proposed framework, we consider monitoring slowly(smoothly) varying elds both in the spatial and in thetemporal domain. Similar to [15], we consider frame-basedmeasurement transmission to the FC. Let Tcoh be the coherencetime of the monitored process over which the process almostdecorrelates in time. Unlike [15], we chose a shorter frameduration T < Tcoh over which the process has sufcientcorrelation in time. The correlation between the consecutiveframes is exploited to reduce the numbers of required mea-surements during reconstruction. The sensing process startsafter the FC broadcasts the frame duration to the sensors.Every T frame duration, a subset of sensors is selected atrandom to conduct measurements; see Fig 2. This can bedone by equipping the sensors with independent, identicallydistributed (i.i.d.) Bernoulli random generator. Each sensordetermines whether it will participate in the sensing processwith some probability. Total number of sensors selected forsampling in a frame is then a random variable with someBinomial distribution. The measurements are then transmittedto the FC using random access. Let Tp be the duration of datapacket containing sensor measurement and the node identier.Each node picks a random transmission delay uniformly in[0, T Å| Tp] and transmits the packet to the gateway. In thisrandom access, there is a possibility of collision of packets.A collision occurs if packets from different sensors overlap intime and interfere each other while reaching to the gateway.A key idea of the proposed framework is to let the gatewayssimply discard the colliding packets. Motivated by the theoryof CS, the FC does not care what specic nodes were selected,as long as (i) the selected subsetis chosen uniformly atrandom, and (ii) there are sufciently many collision-freepackets received to allow reconstruction of the frame. Let Kdenotes the numbers of collision-free packets received at theFC during one frame. This is a random variable who valuedepend upon the sensing probability of each sensor node. Forsmall sensing probability, number of measurements will besmall, thus less collisions, but poor quality of reconstruction.On the other hand, increasing sensing probability will resultin large number of measurements that could improve thequality of reconstruction, but after certain limit,this willincrease collisions of packets reaching the gateway. In order tominimize the overall energy consumption of the network, onehas to select the smallest value of sensing probability whilemaintaining reasonable quality of reconstruction. Thus, there istrade-off in choosing sensing probability. For analytical studyof probability distribution of K, please refer to [15].III. DEPLOYMENT AND LOCALIZATION OF SENSOR NETWORKTraditional ways of capturing a spatio-temporal eld, i.e.,following the Nyquist sampling theory, would require deploy-ing sensors at regular interval grids at least twice dense thanthe highest spatial frequency of the eld. This can be verytedious and time consuming task [3], [4]. Theory of CS alle-viates this: the framework consider the opportunistic randomdeployment of sensors. However, it necessitates to localizethe sensors before starting sensing process. Localization needsminimum numbers of anchors with known positions. Theseanchors need to be deployed carefully in the ROI, such thatthey avoid certain geometric conditions and covers the ROIacoustically. We consider anchors lie on the sea surface withtheir acoustic modems are hanging in water. Few of themare hanging just few (1 to 2) meters deep, and few of themare hanging more deeper depending upon the depth of sensornodes to be localized. Random deployment of large numbersof sensor nodes and few deliberate deployments of anchorsis more economic than the traditional regular grid scheme.Moreover, if the nodes drifts over time, we can easily re-localize them, thanks to the positioning scheme we presentbelow.Sensor network localization techniques can be broadly clas-sied into two categories: range-based and range-free. Range-based techniques measure or estimate distances to a smallnumber of anchor nodes via time-of-arrival (ToA) or time-difference-of-arrival (TDoA) and then apply triangulation ormultilateration or relaxed convex optimization [20], [21] toestimate the coordinates. The minimum necessary conditionis that there should be at least three non-collinear anchorsfor 2-D space localization and atleast four non-coplanar(and three of them should be non-collinear) for 3-D spacelocalization. Range-free techniques explore the local topol-ogy and derive the position estimate from the location ofsurrounding anchor nodes. Generally, range-based techniquesprovide better position accuracy than range-free localization.ToA or TDoA approaches require time synchronization if one-way sound ying time is counted on; otherwise, a ping-pong-style round trip propagation delay needs to be measured. Inunderwater environment, precise time synchronization amongthe nodes is hard to achieve due to the characteristics of soundwave in water [3]. Due to long propagation delay of acousticsignal, the ping-pong-style needs long time before all sensornodes nish pinging all the anchors. In this paper, we presentUPS, a silent positioning scheme rst proposed in [22], andsuggest geometrical congurations of the anchors to coverlarge localizable space and easy extension of the localizablespace.A. Silent positioning schemeHere, we present the details of the UPS for UWASNsin 3D space. UPS requires very few anchors (three for 2-D space and four for 3-D space) with long-range beaconssignal. Three anchors lie on the surface and one lies deepinto ocean. Example of geometric conguration of anchors areshown in rst row of the Fig. 7. The anchors and the sensorshave their own local timers and do not need synchronizationamong them. UPS consists of two steps: (i) sensor nodes detectTDoAs from the four anchors and transform them into rangedifferences, and (ii) sensors do trilateration to transform theserange estimates into coordinates.First step of UPS computes the range differences betweendA and dB, dC, dD, respectively.Step 1 Range Difference Computation: Let A be the masteranchor, which initiates a beacon signal. At times t1, tB, tC, andtD the sensor S and anchors B, C, and D receive the beaconsignal, respectively. At time tB  tB B replies anchor A witha beacon signal conveying information tB Å| tB = tB. Thissignal reaches S at time t2. After receiving signal from A andB, at time tC, C replies to A with a beacon signal conveyinginformation tC Å| tC = tC. This signal reaches S at t3. Afterreceiving signal from A, B, and C, at time tD D replies to Awith a beacon signal conveying information tD Å| tD = tD.This signal reaches S at time t4. Based on triangle inequality,t1 < t2 < t3 < t4. Note that all the arrival times are measuredlocally. Let the TDoA be t1 = t2Å|t1, t2 = t2Å|t1, t3 =t3 Å| t1. Then, the range differences will bewhere v is velocity of sound, and dAB, dAC, dAD are rangesbetween anchor A and the remaining anchors B, C, and D,respectively.The second step involves computing coordinates using therange differences. This step is computationally inexpensive:just involves inverting a 3 Å~ 3 matrix and nding a square-root. Thus, it can implemented on low-powered processingunit.Step 2 Location Computation: We have:where we represent xTx = x2.And for i Å∏ B, C, DBy subtracting (1) from (2), we obtain, for i Å∏ {B, C, D}:Let a, b be vectors such that:Let x = x Å| b, then using (4) we get :Thus, we have:From (1) and (6), we get:Coordinate of S is found by these steps:1) Solve (5) to obtain the vectors a and b2) Solve the quadratic equation (7) to obtain the range dA3) If one positive solution exits, then use (6) to obtain thecoordinate x of S, otherwise no unique solution exists.If (7) does have two positive solutions, we can use some sanitycheck to eliminate one of the solution, e.g., if the sensor nodehas depth sensor, then we can eliminate the infeasible solution.The errors in measurements of TDoA are inevitable, andcan occur due to the noise in the electronics, Doppler effect,variable acoustic speed underwater and multipath. In order tominimize the effects of the errors in TDoA, we can repeat thebeacon signaling cycle described in Step 1 and have severalcopies of the range differences di, i = {B, C, D}, and usetheir average (assuming errors from i.i.d. Gaussian distribu-tions) or median (assuming errors are from i.i.d. uniformdistributions). The latter is often the case since the errors dueto variable acoustic speed and multipath can be approximatelymodeled by Uniform distribution. Please refer to [22], [23]for further discussion on sources of errors and theoreticalerror analysis. Note how in the case that the sensor nodesdrift slowly over the time, the beacon signaling cycle can beeasily repeated to re-estimate their location. At the end of thelocalization phase, the estimated locations of the nodes aretransmitted to the FC using TDMA [6].B. Simulation: LocalizationThe location estimated using TDoA is given by intersectionof 3-D hyperboloids whose foci are the anchors. Uniquelylocalizable space around the anchors depends upon the geo-metric conguration of the anchors. The anchors should beplaced such that it covers maximum space where the sensorscan be localized uniquely while being in acoustic ranges ofthe anchors. Finding an optimal conguration of anchors for agiven ROI and acoustic ranges of the anchors is a difcultproblem. Thus, we conducted simulation to nd uniquelylocalizable space for different practically deployable geometriccongurations. In our simulation, we considered three anchorsA, B, C on the surface and the fourth anchor D at certain depthbelow surface. All the anchors have acoustic range of 4000meters. No noise was introduced in the TDoA measurements.In Fig. 7, we show only the four congurations, namely Cong#1, Cong #2, Cong #3, and Cong #4 and their uniquelylocalizable spaces. We considered 400 sensors at regular gridwithin 2-D region dened by [Å|2000, 2000] Å~ [Å|2000, 2000]lying at different depths. In the rst three congurations, thesurface anchors form equilateral triangle with a side length of1000 meters, while in the last conguration, they form right-angled triangle with two sides of length 1000 meters. In allcongurations, the fourth anchor lies at depth of 500 meters.We can see that the space very near to any anchor is notlocalizable, but after certain depth, the Cong #1 and Cong#3 cover largest symmetrical localizable space, while Cong#4 covers unsymmetrical localizable space, which may notbe suitable in the case when anchors have omnidirectionalacoustic range. The Cong #2 has the smallest localizablespace. Table I shows the number of localized nodes out of400 nodes at different depths. We found that the optimalcongurations is the one when the surface anchors form anequilateral triangle and the fourth anchor has certain offsetfrom their centroid. Any variation from this congurationresulted in shrinking the localizable space. Moreover, it isimportant to note that the sensor nodes lying below the depthof the anchor D are localizable, thus it is not necessary todeploy the anchor D very deep in order to localize deepersensor nodes.We also studied the effect of errors in TDoA measurements.We considered two types of statistical source of errors: i.i.d.Gaussian and i.i.d. Uniform distribution. In the simulation,we considered N = 4000 sensor nodes spread over aregular grid within the space dened by [Å|2000, 2000] Å~[Å|2000, 2000] Å~ [50, 2000], and Cong #1 for the anchors.Speed of the sound in water was considered to be 1500meters/sec, i.e. an error of 1 millisecond corresponds to 1.5meters. The locations of the nodes were estimated using mea-surements taken over ve beacon signaling cycles. The TableII presents the results of simulation: root-mean-square-errorin the estimated locations andthe number localized nodes out 4000 nodes. We see thatrepeating the beacon signaling for certain number of cyclesmitigates very well the effect of errors in measurements.Moreover, we can easily increase our condence on the es-timated locations by comparing the results from few differentcongurations, e.g. Cong #1 and Cong #2, at expense ofadding few more anchors as D. This will also extend thelocalizable space. In fact, extending the localizable space toan existing network can be easily accomplished by adding fewmore anchors to a existing conguration. e.g. by deploying asurface and an underwater anchor node, and including the newanchors into the beacon signaling cycles.IV. SPATIO-TEMPORAL SENSINGIn Section II we described a generic scenario and sensornode localization in 3-D space, but here, we consider 2-Dspace for demonstrating the spatio-temporal sensing, whichcan be easily extended to 3-D space. For this, let assumethat the ROI is discretized in to I Å~ J = N regular intervalzones over which M sensor nodes are deployed uniformly atrandom. During a frame, let K collision free measurementsy Å∏ RK reach to the FC. Let u Å∏ RN denotes the eldmap we like to estimate from the measurements. Note wedenote a 2-D eld (matrix) as a vector by stacking its columns.The measurements from uniformly at random sensors can bemodeled as:where É≥ Å∏ RKÅ~N is sensing matrix consist of K rows ofan identity matrix selected uniformly at random. This randomsensing matrix accounts for both the randomly selected sensorsfor measurement and random collisions at FC. If the eldu is sparse in a representation basis Éµ Å∏ RNÅ~N , then wehave u = Éµv, where v has very few non-zero elements. Thetheory of CS [7], [8] states that as long as the eld is S-sparse in the representation basis Éµ and K correctly receivedmeasurements, picked uniformly at random, is greater thanNs = CS log N, then with very high probability the eldu can be estimated exactly by solving the following convexoptimization:Here C is a constant independent of both N and S. Moreover,we also assume that the matrix É≥Éµ admits the restrictedisometry property (RIP) [7]. With high probability, a randomsensing matrix such as É≥ in our case achieves RIP. Theoptimization problem (9) is referred to as basis pursuit [24]and can be solved efciently by plenty of solvers, e.g. see[25], [26, p. 41] and references within.Usually, the elds are not exactly sparse but nearly sparse.the measurements contains some noise due toMoreover,characteristics of sensors. Under this condition the observationmodel is written as:where we consider e to be i.i.d. Gaussian noise. CS theory stillguarantees that the eld can be recovered with good accuracyby solving the following convex optimization:where  > 0 bounds the amount of the noise in the measure-ments. This is usually referred to as robust signal recoveryproblem. Problem (12) can also be equivalently written as:where É… > 0 is a regularization parameter to balance the twinobjectives of minimizing the error and sparsity, and is directlyproportional to the strength of noise in the measurements. Thisregularized reconstruction (13) is usually preferable over theprevious formulation (12) for it can be efciently solved bysolvers in [26][30] given that representation basis Éµ admitsa fast matrix-vector multiplication.In this paper, we choose Discrete Cosine Transform (DCT)as representation basis Éµ for it can sparsely represent thesmoothly varying eld and admits a fast matrix-vector mul-tiplication using Fast Fourier Transform [31]. As discussedabove, along with exploiting the smoothness of the eld inspatial domain, we also exploit the smoothness of the slowlyvarying eld along temporal domain. Two consequent framesof a slowly varying eld have high correlation between themwith overwhelming probability. Thus, given that we have theestimate of the previous (t Å| 1)-th frame, we propose toreconstruct t-th frame by solving following optimization:get the estimated frame as ut = Éµvt. In this above formula-tion, the closeness between two consequent frames is imposedby the third term and parameter Éƒ  0 controls its effect;higher value of Éƒ imposes higher correlation between twoconsequent frames.A. Simulation: Field ReconstructionTo validate the proposed spatio-temporal eld reconstruc-tion, we considered synthetic temperature eld consists of 500frames of spatial dimension of 42Å~42 = 1764 zones. The eldvaries smoothly along the spatial and temporal domain exceptat every hundredth frame there are bumps of temperature spotsat random locations; see Fig. 8, which shows the differentframes. We considered 1323 sensor nodes deployed uniformlyat random in those zones. During each frame a subset sensornodes selected uniformly at random perform measurementsand transmit them to the FC. We dene compression ratio cas number of correctly received measurements at FC during aframe divided by total number of zones in the eld. To measurethe quality of reconstructed eld, we used root-mean-square-error (RMSE) criterion dened as. To solve theoptimization problem (9), we used the ADMM presented in[26, Sec 6.2] and for problems (13) and (14), we used FISTAwith backtracking proposed in [28, Sec 3].For a given eld, the minimum number of measurementsNs required to reconstruct the eld with high accuracy isa prerequisite to perform compressive sensing. Since in oursimulation, the eld is changing with time, Ns cannot bethe same for all the frames. Thus, the rst task is to nda value of Ns that will result good quality reconstruction overall the frames. To do so, we selected few random framesand reconstructed them individually by solving the problem(12) for different values of compression ratio c during themeasurements. We found c = 0.25 i.e., Ns = 441 is wellsuited for all the frames as shown in the plot in Fig. 3.Increasing further the value of c did not signicantly changedRMSE of the reconstructed frames.Next, we considered reconstruction from noisy measure-ments. The temperature eld in our simulation varies between5 to 20 degree Celsius. During the sensing phase, we xedc = 0.25 and corrupted the measurements in each frame byi.i.d. Gaussian noise with zero mean and standard deviation(É– = 0.25). In this case, the frames are reconstructed bysolving problem (14). We did warm-starts of the FISTAalgorithm for the reconstruction of the consecutive frames.Here, we have two parameters É… and Éƒ to be tuned to achievegood quality of reconstruction. To nd best values the twoparameters, we performed a grid-search in (É…, Éƒ) space: wexed the value of Éƒ and reconstructed the frames for differentvalues of É…, and repeated this for different values of Éƒ. Wefound that the pair É… = 0.1, Éƒ = 0.5 resulted the best possiblereconstruction i.e. the lowest RMSE over all frames. Figure4 shows the RMSE for all the frames for different valuesof É… when Éƒ is xed at 0.5. Similarly, Fig. 5 shows theRMSE for all the frames for different values of Éƒ when É…is xed at 0.1. From the latter plots, we can easily see thatthe quality of reconstruction drastically improves when weimpose the correlation betweens the consecutive frames. Thisindicates that including the information from previous frameinto the reconstruction of current can lower the number ofmeasurements required to reconstruct the consecutive frames.This is conrmed by the plots in Fig. 6, which shows thatwe need to increase the value of c to 0.6 when using noinformation from previous frame, i.e., Éƒ = 0, to achieve thesimilar quality of reconstruction when c = 0.25 and Éƒ = 0.5.This validates experimentally our proposed compressive sens-ing scheme, which requires less number of measurements andcollisions, and thus prolongs the life-time of each sensor node.We also see bumps in RMSE in the plots at the certain frames(e.g., at frame number 100, 200, 300, and 400). This is dueto the fact that the temperature eld changes drastically atthose frames. In Figure 5, we see that for smaller values of Éƒ,the reconstruction recovers quickly from those bumps effects,but the RMSE remains higher for all the frames, whereas forthe larger values of Éƒ, the reconstruction recovers slowly, butreaches to lower value of RMSE. There is always a trade-off, and one can select the value of Éƒ depending upon theapplication, but it is always preferable to choose Éƒ > 0.V. CONCLUSIONWe presented a framework for spatio-temporal monitoringof ocean environment by UWASNs. The spatio-temporal eldreconstruction is based on compressive sensing, which allowsrandom deployment of the sensor nodes in the ROI, performrandom measurements and use random channel access totransmit the data to a FC. To this end,we considered asilent positioning scheme for randomly deployed sensors, andstudied optimal geometric congurations of anchor nodes tomaximise the localizable space. For slowly varying eld, thereis high correlation between consecutive frames. We proposedto utilize this information during reconstruction of consecutiveframes. This resulted in a signicant reduction of the requirednumber of measurements needed to achieve reasonable qualityof the estimated eld. Utilizing silent positioning for sensornodes and compressive sensing for spatio-temporal eld re-construction from randomly collected measurements save bothenergy and bandwidth, which ultimately enables long-termdeployment of UWASNs.In sensing phase, we chose the value of the regularizationparameter Éƒ empirically. Future work will try to theoreticallypredict its value based on correlation between previouslyreconstructed frames. Rather than using a centralized gatheringof measurements and eld reconstruction, we think that adistributed eld reconstruction algorithm can mitigate theproblems with centralized processing scheme. For example,each anchor may act as a local fusion center and collaboratewith each other for global eld reconstruction. Based on thesimulation results, we are presently developing the hardwareand the software needed for real-time deployment of theproposed framework.